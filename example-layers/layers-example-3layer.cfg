# 4 tower convnet layers definition

[data1]
type=data
dataIdx=0

[data2]
type=data
dataIdx=1

[data3]
type=data
dataIdx=2

[data4]
type=data
dataIdx=3

[labels]
type=data
dataIdx=4

#------------tower 1----------------

#------------first layer--------------
# input : 224 x 224 x 3
[conv1.1]
type=conv
inputs=data1
channels=3
filters=16
padding=0
stride=2
filterSize=7
initW=0.01
initB=0
sharedBiases=1
partialSum=1
neuron=relu

[rnorm1.1]
type=cmrnorm
inputs=conv1.1
channels=16
size=5


[pool1.1]
type=pool
pool=max
inputs=rnorm1.1
sizeX=3
stride=2
channels=16
neuron=relu  




#------------second layer--------------
[conv1.2]
type=conv
inputs=pool1.1
channels=16
filters=32
padding=0
stride=2
filterSize=5
neuron=relu  
initW=0.01
initB=0
partialSum=1
sharedBiases=1

[rnorm1.2]
type=cmrnorm
inputs=conv1.2
channels=32
size=5


[pool1.2]
type=pool
pool=max
inputs=rnorm1.2
sizeX=3
stride=2
channels=32
neuron=relu  



#------------third layer--------------
[conv1.3]
type=conv
inputs=pool1.2
filters=64
padding=0
stride=1
filterSize=3
channels=32
initW=0.01
initB=0
partialSum=1
sharedBiases=1
neuron=relu


[rnorm1.3]
type=cmrnorm
inputs=conv1.3
channels=64
size=5


#----------------tower 2----------------

# input : 224 x 224 x 3
[conv2.1]
type=conv
inputs=data2
channels=3
filters=16
padding=0
stride=2
filterSize=7
initW=0.01
initB=0
sharedBiases=1
partialSum=1
neuron=relu  

[rnorm2.1]
type=cmrnorm
inputs=conv2.1
channels=16
size=5


[pool2.1]
type=pool
pool=max
inputs=rnorm2.1
sizeX=3
stride=2
channels=16
neuron=relu  


#------------second layer--------------
[conv2.2]
type=conv
inputs=pool2.1
channels=16
filters=32
padding=0
stride=2
filterSize=5
neuron=relu  
initW=0.01
initB=0
partialSum=1
sharedBiases=1

[rnorm2.2]
type=cmrnorm
inputs=conv2.2
channels=32
size=5


[pool2.2]
type=pool
pool=max
inputs=rnorm2.2
sizeX=3
stride=2
channels=32
neuron=relu  



#------------third layer--------------
[conv2.3]
type=conv
inputs=pool2.2
filters=64
padding=0
stride=1
filterSize=3
channels=32
initW=0.01
initB=0
partialSum=1
sharedBiases=1
neuron=relu

[rnorm2.3]
type=cmrnorm
inputs=conv2.3
channels=64
size=5



#---------- end of tower 2---------

#----------------tower 3----------------

# input : 224 x 224 x 3
[conv3.1]
type=conv
inputs=data3
channels=3
filters=16
padding=0
stride=2
filterSize=7
initW=0.01
initB=0
sharedBiases=1
partialSum=1
neuron=relu  

[rnorm3.1]
type=cmrnorm
inputs=conv3.1
channels=16
size=5 

[pool3.1]
type=pool
pool=max
inputs=rnorm3.1
sizeX=3
stride=2
channels=16
neuron=relu  



#------------second layer--------------
[conv3.2]
type=conv
inputs=pool3.1
channels=16
filters=32
padding=0
stride=2
filterSize=5
neuron=relu  
initW=0.01
initB=0
partialSum=1
sharedBiases=1

[rnorm3.2]
type=cmrnorm
inputs=conv3.2
channels=32
size=5


[pool3.2]
type=pool
pool=max
inputs=rnorm3.2
sizeX=3
stride=2
channels=32
neuron=relu  



#------------third layer--------------
[conv3.3]
type=conv
inputs=pool3.2
filters=64
padding=0
stride=1
filterSize=3
channels=32
initW=0.01
initB=0
partialSum=1
sharedBiases=1
neuron=relu

[rnorm3.3]
type=cmrnorm
inputs=conv3.3
channels=64
size=5



#---------- end of tower 3---------

#----------------tower 4----------------

# input : 224 x 224 x 3
[conv4.1]
type=conv
inputs=data4
channels=3
filters=16
padding=0
stride=2
filterSize=7
initW=0.01
initB=0
sharedBiases=1
partialSum=1
neuron=relu  

[rnorm4.1]
type=cmrnorm
inputs=conv4.1
channels=16
size=5


[pool4.1]
type=pool
pool=max
inputs=rnorm4.1
sizeX=3
stride=2
channels=16
neuron=relu  




#------------second layer--------------
[conv4.2]
type=conv
inputs=pool4.1
channels=16
filters=32
padding=0
stride=2
filterSize=5
neuron=relu  
initW=0.01
initB=0
partialSum=1
sharedBiases=1

[rnorm4.2]
type=cmrnorm
inputs=conv4.2
channels=32
size=5


[pool4.2]
type=pool
pool=max
inputs=rnorm4.2
sizeX=3
stride=2
channels=32
neuron=relu  

#------------third layer--------------
[conv4.3]
type=conv
inputs=pool4.2
filters=64
padding=0
stride=1
filterSize=3
channels=32
initW=0.01
initB=0
partialSum=1
sharedBiases=1
neuron=relu

[rnorm4.3]
type=cmrnorm
inputs=conv4.3
channels=64
size=5



#---------- end of tower 4----------

#------------sixth layer--------------

[concat]
type=eltsum
inputs=rnorm1.3,rnorm2.3,rnorm3.3,rnorm4.3
coeffs=1,1,1,1


[fc6]
type=fc
outputs=1000
inputs=concat
initW=0.01
initB=0
neuron=relu


[softmax]
type=softmax
inputs=fc6

[logprob]
type=cost.logreg
inputs=labels,softmax